{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3d28a1-327c-4d1e-b69c-b86ab754ddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries imported 😎\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import nltk \n",
    "import numpy as np \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer ## stemming \n",
    "from nltk.stem import WordNetLemmatizer  ## lemmatization\n",
    "import joblib,os \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences \n",
    "from sklearn.preprocessing import LabelEncoder ,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('libraries imported 😎')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "349645d0-6f25-460c-b7e2-b12622a69268",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading data from the text files \n",
    "\n",
    "train_data = open(\"./Data/train.txt\").readlines()\n",
    "val_data = open(\"./Data/val.txt\").readlines()\n",
    "test_data = open(\"./Data/test.txt\").readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a986b3ce-8dcd-4c90-ba19-3962d8ae3de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03fa62f9-f16b-4f72-b304-bff76bdf2355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "complet_data = train_data + test_data + val_data \n",
    "print(len(complet_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a524209-6a55-4844-afa9-51cd9842344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for temp in complet_data:\n",
    "    complete = temp.split(';')\n",
    "    if len(complete)==2:\n",
    "        x.append(complete[0])\n",
    "        y.append(complete[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ace463b-dac6-48b5-a4d5-fdd63946b80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sadness', 'anger', 'love', 'surprise', 'fear', 'joy']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[]\n",
    "for item in y:\n",
    "        if item not in labels:\n",
    "            labels.append(item)\n",
    "labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0605f5cc-53fa-494a-8548-0d8d6b6b8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text cleaning \n",
    "# 1. lower case convert all message \n",
    "# 2. a-z0-9   other characters \n",
    "# 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec0144-333d-48b1-a014-e9ad361a2161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89693722-a988-4a59-8fb1-7c6897a64dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text cleaning function applying on each and every raw message \n",
    "def text_cleaning(sentences,stemming):\n",
    "    cleaned_data = []\n",
    "    for sentece in sentences: \n",
    "        message = sentece.lower()\n",
    "        message = re.sub('[^a-z0-9 ]',\"\",message)\n",
    "        ls_of_words = nltk.word_tokenize(message)\n",
    "        ls_of_word_without_stopwords = [word for word in ls_of_words if word not in stopwords.words('english')]\n",
    "        stemmed_words = [stemming.stem(word) for word in ls_of_word_without_stopwords ]\n",
    "        message = \" \".join(stemmed_words)\n",
    "        cleaned_data.append(message)\n",
    "    return cleaned_data\n",
    "\n",
    "stem = PorterStemmer()\n",
    "cleaned_data = text_cleaning(x,stemming=stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d6e6ff-eaa9-4e10-906c-fdc8deb4b54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved your cleaned data!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('models',exist_ok=True)\n",
    "joblib.dump(cleaned_data,\"./models/cleaned_data.lb\")\n",
    "# cleaned_data = joblib.load(\"./models/cleaned_data.lb\")\n",
    "print(\"successfully saved your cleaned data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a53e7-53df-4028-a484-2ae58bb2cd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be3e92db-b4b2-4711-9355-59f023353ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake\n",
      "['go', 'feeling', 'hopeless', 'damned', 'hopeful', 'around', 'someone', 'cares', 'awake']\n",
      "['go', 'feel', 'hopeless', 'damn', 'hope', 'around', 'someon', 'care', 'awak']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'go feel hopeless damn hope around someon care awak'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## trying  on a sinlgle message \n",
    "ls_of_stopwords = stopwords.words('english')\n",
    "print(x[1])\n",
    "single_message = x[1].lower()\n",
    "single_message = re.sub('[^a-z0-9 ]',\"\",single_message)\n",
    "ls_of_words = nltk.word_tokenize(single_message)  # single_message.split()\n",
    "ls_of_word_without_stopwords = []\n",
    "for word in ls_of_words: \n",
    "    if word not in ls_of_stopwords:\n",
    "        ls_of_word_without_stopwords.append(word)\n",
    "print(ls_of_word_without_stopwords)\n",
    "stem = PorterStemmer()\n",
    "stemmed_words = []\n",
    "for word in ls_of_word_without_stopwords: \n",
    "    stemmed_words.append(stem.stem(word))\n",
    "print(stemmed_words)\n",
    "\" \".join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab042279-feb3-4d6e-8735-60262a2ad641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88fc2d12-b41e-4d98-9089-606ae0d4db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved your tokenizer at this location : './models/tokenizer.lb'\n"
     ]
    }
   ],
   "source": [
    "## Tokenaization \n",
    "tokenizer = Tokenizer(oov_token=\"<nothing>\")\n",
    "tokenizer.fit_on_texts(cleaned_data)\n",
    "joblib.dump(tokenizer,'./models/tokenizer.lb')\n",
    "print(\"successfully saved your tokenizer at this location : './models/tokenizer.lb'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af6c3c72-61a2-4258-9a58-0cc590d2dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78ef78b5-93c2-47b0-91b1-f3cc41855ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_counts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "025611d3-8a94-401a-a5dd-44d6a09999a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = tokenizer.texts_to_sequences(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5011cbdd-5574-450f-92f4-682f280917e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7151c8f6-4f10-42c4-b6c8-e24c58290d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'didnt feel humili'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b03fc307-c490-4a79-ba01-bbc56b23c312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 2, 522]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9946d07c-9490-4ea5-8bb6-35363e6308a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8273e59-a5d1-444e-8c72-8cf1a7634d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your maximum length is :  35\n"
     ]
    }
   ],
   "source": [
    "len_of_message = []\n",
    "for i in range(len(tokenized_data)):\n",
    "    len_of_message.append(len(tokenized_data[i]))\n",
    "print(\"Your maximum length is : \",max(len_of_message))\n",
    "# maximum length  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "061b653d-1480-4a4b-9257-2ff0749dc4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your maximum length is :  35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Your maximum length is : \",max(list(map(len,tokenized_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8117bfbe-fe02-468b-9e15-6e981bbe95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(tokenized_data,maxlen=35,padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aca60da-abfd-4e31-bd46-c7eecc6062f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  61,    2,  522, ...,    0,    0,    0],\n",
       "       [  10,    2,  419, ...,    0,    0,    0],\n",
       "       [   4, 1230,  431, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   2,  194,  157, ...,    0,    0,    0],\n",
       "       [ 328,    2,  175, ...,    0,    0,    0],\n",
       "       [   2,    3,  916, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b10dfc98-9e4e-4039-9931-1dd3141b6482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sadness': 0, 'anger': 1, 'love': 2, 'surprise': 3, 'fear': 4, 'joy': 5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[]\n",
    "for item in y:\n",
    "        if item not in labels:\n",
    "            labels.append(item)\n",
    "label_dict = {label:i for i , label in enumerate(labels)}\n",
    "label_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eff6cdb4-bce0-4e24-aa5c-4d45b835ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder ,OneHotEncoder\n",
    "# automation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80814ada-fe8b-4016-86f3-ef6a2fba3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c2f31de-645f-4686-af5f-1d617bd89c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 0, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5c0788f-5c6c-47b4-b577-d09264de3d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'], dtype='<U8')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "447bbcab-c380-4da1-a3c0-921d0a6be1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/label_encoder.lb']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(label_encoder,'./models/label_encoder.lb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ab001c7-8187-4c1f-ac0d-fde170e34ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 0, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences    # <====  X DATA  cleaned data \n",
    "Y            # <====  Y DATA label \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c86d0fb1-36af-4a93-b7a7-42fe7cdf6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test splitting \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(sequences,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c700cbf-303d-486d-b4bc-fa80ea2b755a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ranjit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import LSTM , Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(units=128, input_shape=(35, 1), return_sequences=True),\n",
    "    LSTM(units=64),\n",
    "    Dense(units=6, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db387589-4eaa-403a-95ee-1f706afee499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 169ms/step - accuracy: 0.3275 - loss: 1.5959 - val_accuracy: 0.3217 - val_loss: 1.5773\n",
      "Epoch 2/5\n",
      "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 206ms/step - accuracy: 0.3353 - loss: 1.5800 - val_accuracy: 0.3410 - val_loss: 1.5700\n",
      "Epoch 3/5\n",
      "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 150ms/step - accuracy: 0.3357 - loss: 1.5752 - val_accuracy: 0.3460 - val_loss: 1.5678\n",
      "Epoch 4/5\n",
      "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 163ms/step - accuracy: 0.3257 - loss: 1.5759 - val_accuracy: 0.3410 - val_loss: 1.5700\n",
      "Epoch 5/5\n",
      "\u001b[1m532/532\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 213ms/step - accuracy: 0.3422 - loss: 1.5699 - val_accuracy: 0.3503 - val_loss: 1.5681\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=5,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2a300-0f83-4e82-9b7b-c523cc438c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestCLassifier \n",
    "# obj = RandomForestCLassifier()\n",
    "# obj.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e733804b-b5bb-4d8b-a25d-17fdc749177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step\n"
     ]
    }
   ],
   "source": [
    "# prediction \n",
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65faa4d3-5115-481c-8bb5-02a3acf3140c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 865, 1403, 2457, 2029, 1403, 2306], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.argmax(prediction,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "336b303e-c4ed-43fc-9f90-64dc08e659ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "929f69af-9ebe-47da-9f16-83941bd264f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "130fa010-a91d-49e8-accb-345d027a9510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 2, ..., 4, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5681244-85f3-43b8-8fbd-678320534d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame({'actual':y_test,'prediction':prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8c46b3f-2187-4455-a7ef-2c7baf139df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'sadness', 1: 'anger', 2: 'love', 3: 'surprise', 4: 'fear', 5: 'joy'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dictionary = {value:key for key , value in label_dict.items()}\n",
    "label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "210e3f74-f00f-4db0-9686-91c442eae91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual'] = df['actual'].map(label_dictionary)\n",
    "df['prediction'] = df['prediction'].map(label_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "364751f5-7f3a-4a48-bb4e-93efd37f17a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sadness</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>joy</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anger</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sadness</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>anger</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sadness</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sadness</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>anger</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>surprise</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fear</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>anger</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>sadness</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>love</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual prediction\n",
       "0       fear       love\n",
       "1      anger       love\n",
       "2       love       love\n",
       "3       love       love\n",
       "4       fear       love\n",
       "5       fear       love\n",
       "6    sadness       fear\n",
       "7        joy       love\n",
       "8       fear       love\n",
       "9       love       love\n",
       "10      fear       love\n",
       "11      love       love\n",
       "12     anger       love\n",
       "13   sadness       fear\n",
       "14      love       love\n",
       "15      love       love\n",
       "16      love       love\n",
       "17      love       love\n",
       "18     anger       love\n",
       "19   sadness       love\n",
       "20      fear       love\n",
       "21      fear       love\n",
       "22      love       love\n",
       "23      love       love\n",
       "24      love       love\n",
       "25      love       love\n",
       "26   sadness       love\n",
       "27     anger       love\n",
       "28      love       love\n",
       "29  surprise       fear\n",
       "30      fear       love\n",
       "31      love       love\n",
       "32      fear       love\n",
       "33     anger       love\n",
       "34      love       love\n",
       "35      love       love\n",
       "36   sadness       love\n",
       "37      love       fear\n",
       "38      love       love\n",
       "39      love       love"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e65193-3e82-4fa1-87fe-4352487d8d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using RNN \n",
    "# sequential SimpleRNN model defining\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(32,input_shape=(35,1),return_sequences=False))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "## compiling the model\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "# return_sequence = False  --> means if you don,t want to stack again this model then specify False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "021d2899-4e20-4ff5-a90d-e9609e964cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "## model save\n",
    "import os\n",
    "os.makedirs('models',exist_ok=True)  \n",
    "model.save('./models/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e35a7bcd-0376-49cd-bb4a-c634fbae9852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "## to load the tensorflow models \n",
    "from tensorflow.keras.models import  load_model \n",
    "loaded_model = load_model('./models/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "562c28e4-629e-4b8e-b58b-73aa4fea0730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                   </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">      Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└────────────────────────────────┴────────────────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m66,560\u001b[0m │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m49,408\u001b[0m │\n",
       "├────────────────────────────────┼────────────────────────┼──────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │          \u001b[38;5;34m390\u001b[0m │\n",
       "└────────────────────────────────┴────────────────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,360</span> (454.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m116,360\u001b[0m (454.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,358</span> (454.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m116,358\u001b[0m (454.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
